{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tar -C /tmp/ayu -zvxf xyz.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,pickle,time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from multiprocessing import Pool \n",
    "import shutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['亞太',\n",
       " '台灣碩網',\n",
       " '中嘉寬頻',\n",
       " '凱擘',\n",
       " '台灣之星',\n",
       " '遠傳',\n",
       " '台哥大',\n",
       " '台基開發',\n",
       " '中華電信',\n",
       " '台灣固網',\n",
       " '台固媒體']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"../data_hdd4t/\"\n",
    "company_names = next(os.walk(root_dir))[1]\n",
    "company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_untar(dir_path):\n",
    "    total, used, free = shutil.disk_usage(dir_path)\n",
    "    if (free<total*0.05) or (free // (2**30) < 130):\n",
    "        cmd = ['rmdir',dir_path]\n",
    "        p = subprocess.Popen(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE, shell=False)\n",
    "        out, err = p.communicate()\n",
    "        print(\"!Error:\", err, '!')\n",
    "        print(dir_path)\n",
    "        return dir_path\n",
    "    else:\n",
    "        cmd = [\"tar\",\"-C\", dir_path,\n",
    "           \"-zvxf\", dir_path.replace('_dir','.tar.gz')]\n",
    "        p = subprocess.Popen(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE, shell=False)\n",
    "        out, err = p.communicate()\n",
    "        print(\"!Error:\", err, '!')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For ISP's Pcap\n",
    "parallel by function name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 38383.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data_hdd4t/中華電信/pcap/snort.2020-01-09_dir',\n",
       " '../data_hdd4t/中華電信/pcap/snort.2020-01-11_dir',\n",
       " '../data_hdd4t/中華電信/pcap/snort.2020-01-10_dir']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "paths = []\n",
    "days = ['2020-01-09','2020-01-10','2020-01-11'] #指定日期，清空掉就是全部日子\n",
    "for name in tqdm(company_names):\n",
    "    if name != '中華電信': #指定電信公司，註解掉就是全部\n",
    "        continue\n",
    "#     print('=== Running:',name,'===')\n",
    "    pcap_path = root_dir + name + '/pcap/'\n",
    "    file_names = next(os.walk(pcap_path))[2]\n",
    "    file_names = list(filter(lambda f: f.endswith(\".tar.gz\"), file_names))\n",
    "    new_dir_names = [x.replace('.tar.gz','_dir') for x in file_names]\n",
    "    for dir_name in new_dir_names:\n",
    "        path = pcap_path+dir_name\n",
    "        try:\n",
    "            if days != []:\n",
    "                for day in days:\n",
    "                    if day in path:\n",
    "                        os.makedirs(path, exist_ok=True)\n",
    "                        paths.append(path)\n",
    "            else:\n",
    "                os.makedirs(path, exist_ok=True)\n",
    "                paths.append(path)\n",
    "        except NameError:\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            paths.append(path)\n",
    "        \n",
    "paths\n",
    "# paths = []\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f1fbabfb2d0>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f1fbabfb390>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f1fbabfb490>\n",
      "Decompress Time: 1.000000:45.000000:15.102567\n",
      "CPU times: user 5.45 s, sys: 1.95 s, total: 7.4 s\n",
      "Wall time: 1h 45min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "load_start = time.time()\n",
    "pool_result = []\n",
    "pool = Pool() #processes=21\n",
    "for path in paths:\n",
    "    r = pool.apply_async(parallel_untar,(path,))\n",
    "    pool_result.append(r)\n",
    "pool.close()\n",
    "pool.join()\n",
    "for r in pool_result:\n",
    "    print('return:',r)\n",
    "load_end = time.time() - load_start\n",
    "print(\"Decompress Time:\", '{:02f}:{:02f}:{:02f}'.format(load_end // 3600, (load_end % 3600 // 60), load_end % 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove folder recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_hdd4t/中華電信/pcap/snort.2020-01-04_dir/\n",
      "../data_hdd4t/中華電信/pcap/snort.2020-01-10_dir/\n",
      "../data_hdd4t/中華電信/pcap/snort.2020-01-09_dir/\n",
      "../data_hdd4t/中華電信/pcap/snort.2020-01-02_dir/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:04<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_hdd4t/中華電信/pcap/snort.2020-01-11_dir/\n",
      "../data_hdd4t/中華電信/pcap/snort.2020-01-08_dir/\n",
      "../data_hdd4t/中華電信/pcap/snort.2020-01-05_dir/\n",
      "../data_hdd4t/中華電信/pcap/snort.2020-01-06_dir/\n",
      "../data_hdd4t/中華電信/pcap/snort.2020-01-07_dir/\n",
      "../data_hdd4t/中華電信/pcap/snort.2020-01-03_dir/\n",
      "../data_hdd4t/中華電信/pcap/snort.2020-01-01_dir/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name in tqdm(company_names):\n",
    "#     if name == '中華電信': #指定電信公司\n",
    "#         continue\n",
    "    pcap_path = root_dir + name + '/pcap/'\n",
    "    dir_names = next(os.walk(pcap_path))[1]\n",
    "    if dir_names != []:\n",
    "        for folder in dir_names:\n",
    "            shutil.rmtree(pcap_path+folder+'/')\n",
    "            print(pcap_path+folder+'/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For ISPs' honeypot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 420.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data_hdd4t/中華電信/honeypot/2020-01-10/cowrie/cowrie_log_2020-01-10_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-10/cowrie/cowrie_file_2020-01-10_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-10/amun/amun_log_2020-01-10_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-10/amun/amun_file_2020-01-10_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-10/glastopf/glastopf_file_2020-01-10_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-10/glastopf/glastopf_log_2020-01-10_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-10/dionaea/dionaea_log_2020-01-10_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-10/dionaea/dionaea_file_2020-01-10_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-11/cowrie/cowrie_log_2020-01-11_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-11/cowrie/cowrie_file_2020-01-11_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-11/amun/amun_log_2020-01-11_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-11/amun/amun_file_2020-01-11_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-11/glastopf/glastopf_file_2020-01-11_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-11/glastopf/glastopf_log_2020-01-11_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-11/dionaea/dionaea_file_2020-01-11_dir',\n",
       " '../data_hdd4t/中華電信/honeypot/2020-01-11/dionaea/dionaea_log_2020-01-11_dir']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = []\n",
    "days = ['2020-01-09','2020-01-10','2020-01-11'] #指定日期，清空掉就是全部日子\n",
    "for name in tqdm(company_names):\n",
    "    if name != '中華電信': #指定電信公司，註解掉就是全部\n",
    "        continue\n",
    "#     print('=== Running:',name,'===')\n",
    "    hp_path = root_dir + name + '/honeypot/'\n",
    "    date_dir_names = next(os.walk(hp_path))[1]\n",
    "    if days != []:\n",
    "        temp = []\n",
    "        for date in date_dir_names:\n",
    "            for day in days:\n",
    "                if day == date:\n",
    "                    temp.append(date)\n",
    "        date_dir_names = temp\n",
    "    else:\n",
    "        pass\n",
    "    for date in date_dir_names:\n",
    "        hp_date_path = hp_path + date +'/'\n",
    "        hp_names_dir = next(os.walk(hp_date_path))[1]\n",
    "        for name in hp_names_dir:\n",
    "            file_names = next(os.walk(hp_date_path+name+'/'))[2]\n",
    "            file_names = list(filter(lambda f: f.endswith(\".tar.gz\"), file_names))\n",
    "            new_dir_names = [x.replace('.tar.gz','_dir') for x in file_names]\n",
    "            for dir_name in new_dir_names:\n",
    "                path = hp_date_path+name+'/'+dir_name\n",
    "                os.makedirs(path, exist_ok=True)\n",
    "                paths.append(path)\n",
    "        \n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "!Error: b'' !\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d16d4390>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d16d4c90>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d16d4290>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d16d4490>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d16d4690>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d16d4850>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d16d4310>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d163aa90>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d163ab90>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d16d4610>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d163a750>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d163a450>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d163aad0>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d163a650>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d163a810>\n",
      "return: <multiprocessing.pool.ApplyResult object at 0x7f10d163a8d0>\n",
      "CPU times: user 21.8 ms, sys: 41 ms, total: 62.8 ms\n",
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pool_result = []\n",
    "pool = Pool() #processes=21\n",
    "for path in paths:\n",
    "    r = pool.apply_async(parallel_untar,(path,))\n",
    "    pool_result.append(r)\n",
    "pool.close()\n",
    "pool.join()\n",
    "for r in pool_result:\n",
    "    print('return:',r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-01-11'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 3667 GiB\n",
      "Used: 2367 GiB\n",
      "Free: 1113 GiB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "total, used, free = shutil.disk_usage(paths[0])\n",
    "\n",
    "print(\"Total: %d GiB\" % (total // (2**30)))\n",
    "print(\"Used: %d GiB\" % (used // (2**30)))\n",
    "print(\"Free: %d GiB\" % (free // (2**30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "if 1<2 and (2<3:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(pcap_path+new_dir_names[0], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anaconda3  data  data_hdd4t  Download  Leo_code\r\n"
     ]
    }
   ],
   "source": [
    "!ls  ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'anaconda3\\ndata\\ndata_hdd4t\\nDownload\\nLeo_code\\n'\n"
     ]
    }
   ],
   "source": [
    "cmd = [\"ls\",'../']\n",
    "p = subprocess.Popen(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE, shell=False)\n",
    "out, err = p.communicate()\n",
    "print(str(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
