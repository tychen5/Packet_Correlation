{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,pickle,time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pcap\n",
    "* tgz file size\n",
    "* decompressed dir size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pcap_tgz_avg_byte,median: 30502562266.74074 30779884851.0\n",
      "pcap_tgz_avg_GB,median: 28.407724822629934 28.666001605801284\n",
      "pcap_decompress_avg_byte,median: 128667487756.0 148432255191.0\n",
      "pcap_decompress_avg_GB,median: 119.83093596622348 138.23831006046385\n"
     ]
    }
   ],
   "source": [
    "root_dir = '../data_hdd4t/'\n",
    "companies = next(os.walk(root_dir))[1]\n",
    "file_num = 0\n",
    "all_size = []\n",
    "all_size_decompress = []\n",
    "for company in companies:\n",
    "    tgz_path = root_dir+company+'/pcap/'\n",
    "    tgz_files = next(os.walk(tgz_path))[2]\n",
    "    tgz_files = list(filter(lambda f: f.endswith(\".tar.gz\"), tgz_files))\n",
    "    decompress_dir = next(os.walk(tgz_path))[1]\n",
    "    decompress_dir = list(filter(lambda f: f.endswith(\"_dir\"), decompress_dir))\n",
    "    for de_dir in decompress_dir:\n",
    "        now_dir = tgz_path+de_dir+'/'\n",
    "        root_directory = Path(now_dir)\n",
    "        de_size = sum(f.stat().st_size for f in root_directory.glob('**/*') if f.is_file() )\n",
    "        if de_size>0:\n",
    "            all_size_decompress.append(de_size)\n",
    "    for file in tgz_files:\n",
    "        size = os.stat(tgz_path+file).st_size\n",
    "        if size>0:\n",
    "            all_size.append(size)\n",
    "            file_num += 1\n",
    "pcap_tgz_avg_byte = np.mean(all_size)\n",
    "pcap_tgz_median_byte = np.median(all_size)\n",
    "print('pcap_tgz_avg_byte,median:',pcap_tgz_avg_byte,pcap_tgz_median_byte)\n",
    "print('pcap_tgz_avg_GB,median:',pcap_tgz_avg_byte/1073741824,pcap_tgz_median_byte/1073741824)\n",
    "pcap_decompress_avg_byte = np.mean(all_size_decompress)\n",
    "pcap_decompress_median_byte = np.median(all_size_decompress)\n",
    "print('pcap_decompress_avg_byte,median:',pcap_decompress_avg_byte,pcap_decompress_median_byte)\n",
    "print('pcap_decompress_avg_GB,median:',pcap_decompress_avg_byte/1073741824,pcap_decompress_median_byte/1073741824)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[349304443203, 84590073589, 152902404826]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_size_decompress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompress_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "honeypot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hp_tgz_avg_byte,median: 914900827.16 722631070.0\n",
      "hp_tgz_avg_GB,median 0.8520677938684821 0.6730026286095381\n",
      "hp_decompress_avg_byte,median: 3543613865.5 3543613865.5\n",
      "hp_decompress_avg_GB,median 3.300247588660568 3.300247588660568\n"
     ]
    }
   ],
   "source": [
    "root_dir = '../data_hdd4t/'\n",
    "companies = next(os.walk(root_dir))[1]\n",
    "file_num = 0\n",
    "all_size = []\n",
    "all_size_decompress = []\n",
    "for company in companies:\n",
    "    tgz_path = root_dir+company+'/honeypot/'\n",
    "    date_dir = next(os.walk(tgz_path))[1]\n",
    "    for date in date_dir:\n",
    "        day_size = 0\n",
    "        day_size_decompress = 0\n",
    "        hp_type = next(os.walk(tgz_path+'/'+date+'/'))[1]\n",
    "        for hp in hp_type:\n",
    "            tgz_files = next(os.walk(tgz_path+'/'+date+'/'+hp+'/'))[2]\n",
    "            decompress_dir = next(os.walk(tgz_path+'/'+date+'/'+hp+'/'))[1]\n",
    "            decompress_dir = list(filter(lambda f: f.endswith(\"_dir\"), decompress_dir))\n",
    "            for de_dir in decompress_dir:\n",
    "                now_dir = tgz_path+'/'+date+'/'+hp+'/'+de_dir+'/'\n",
    "                root_directory = Path(now_dir)\n",
    "                de_size = sum(f.stat().st_size for f in root_directory.glob('**/*') if f.is_file() )\n",
    "                day_size_decompress = day_size_decompress + de_size\n",
    "            tgz_files = list(filter(lambda f: f.endswith(\".tar.gz\"), tgz_files))\n",
    "            for file in tgz_files:\n",
    "                size = os.stat(tgz_path+'/'+date+'/'+hp+'/'+file).st_size\n",
    "                day_size = day_size + size\n",
    "        if day_size>0:\n",
    "            all_size.append(day_size)\n",
    "            file_num += 1\n",
    "        if day_size_decompress>0:\n",
    "            all_size_decompress.append(day_size_decompress)\n",
    "            \n",
    "hp_tgz_avg_byte = np.mean(all_size)\n",
    "hp_tgz_median_byte = np.median(all_size)\n",
    "print('hp_tgz_avg_byte,median:',hp_tgz_avg_byte,hp_tgz_median_byte)\n",
    "print('hp_tgz_avg_GB,median',hp_tgz_avg_byte/1073741824,hp_tgz_median_byte/1073741824)\n",
    "hp_decompress_avg_byte = np.mean(all_size_decompress)\n",
    "hp_decompress_median_byte = np.median(all_size_decompress)\n",
    "print('hp_decompress_avg_byte,median:',hp_decompress_avg_byte,hp_decompress_median_byte)\n",
    "print('hp_decompress_avg_GB,median',hp_decompress_avg_byte/1073741824,hp_decompress_median_byte/1073741824)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4757513730, 2329714001]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_size_decompress"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
