{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,sys,pickle,glob,gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32.0\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3' #'/home/antslab/anaconda3/bin/python'\n",
    "findspark.init()\n",
    "import pyspark\n",
    "# from pyspark import SparkContext\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pyspark.sql import Row, SQLContext, SparkSession, window\n",
    "from pyspark import SparkConf, SparkContext\n",
    "# Import data types\n",
    "from pyspark.sql.types import *\n",
    "import  pyspark.sql.functions as F\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.local.dir\", \"/mnt/ssd240g/data/Leo_Spark_Home/tmp\")\n",
    "conf.set(\"spark.executor.cores\",\"12\")\n",
    "conf.set(\"spark.driver.memory\",\"79g\")\n",
    "conf.set(\"spark.executor.memory\", \"89g\")\n",
    "conf.set(\"spark.memory.offHeap.enabled\",\"true\")\n",
    "conf.set(\"spark.memory.offHeap.size\",\"75g\")\n",
    "conf.set(\"spark.driver.extraJavaOptions\",\"-Xss19990m\")\n",
    "conf.set(\"spark.driver.extraJavaOptions\",\"-Xms79g\")\n",
    "conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "conf.set(\"spark.kubernetes.pyspark.pythonVersion\",\"3\")\n",
    "conf.set(\"spark.sql.shuffle.partitions\",99990)\n",
    "conf.set(\"spark.driver.maxResultSize\", \"20g\")\n",
    "conf.set(\"spark.sql.debug.maxToStringFields\", 190000)\n",
    "conf.set(\"spark.sql.hive.filesourcePartitionFileCacheSize\",99*1024*1024*1024)\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Test_spark\").config(conf=conf).getOrCreate()\n",
    "# sc = SparkContext(conf=conf)\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", True)\n",
    "import databricks.koalas as ks\n",
    "ks.options.display.max_rows = 20\n",
    "ks.set_option('compute.max_rows', None)\n",
    "# ks.set_option('compute.ops_on_diff_frames', True)\n",
    "ks.set_option('compute.default_index_type', 'distributed')\n",
    "print(ks.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_parquet = '../../data_hdd4t/pcap_process/pcap_spark/2020_01_09/中華電信/parquet/2020_01_09_country_session.parquet/'\n",
    "in_parquet = '../../data_hdd4t/pcap_process/pcap_spark/2020_01_10/中華電信/parquet/2020_01_10_country_session_withtime.parquet/'\n",
    "\n",
    "# df = pd.read_parquet(in_parquet)\n",
    "# df\n",
    "kf = ks.read_parquet(in_parquet)\n",
    "# df = kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['frame.time_epoch', 'session_lifetime', 'session_packets',\n",
       "       'tcp.window_size_value.avg', 'tcp.window_size_value.max', 'tcp.srcport',\n",
       "       'tcp.dstport', 'tcp.flags.ack', 'tcp.flags.fin', 'tcp.flags.push',\n",
       "       'tcp.flags.reset', 'tcp.flags.syn', 'ip.src', 'ip.dst', 'ip.ttl.avg',\n",
       "       'ip.proto', 'frame.protocols.common', 'frame.len.sum', 'city',\n",
       "       'subdivisions', 'latitude', 'longitude', 'domain', 'isp', 'network',\n",
       "       'country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.15 ms, sys: 3.14 ms, total: 5.29 ms\n",
      "Wall time: 18.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf1 = kf[['tcp.dstport','domain','ip.src','frame.time_epoch']] # 需要加入time\n",
    "allgby = kf1.groupby(['tcp.dstport','domain'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allgby"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
