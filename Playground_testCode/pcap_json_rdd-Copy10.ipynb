{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row, SQLContext, SparkSession, window\n",
    "from pyspark import SparkConf\n",
    "# Import data types\n",
    "from pyspark.sql.types import *\n",
    "conf = SparkConf()\n",
    "conf.setMaster(\"local[6]\")\n",
    "conf.set(\"spark.network.timeout\",\"800s\")\n",
    "conf.set(\"spark.driver.memory\",\"100g\")\n",
    "conf.set(\"spark.memory.storageFraction\",\"0.2\")\n",
    "conf.set(\"spark.driver.maxResultSize\",\"0\")\n",
    "spark = SparkSession.builder.appName(\"pcap_analyzer\").config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multipleline\n",
    "pcapPath = \"/home/antslab/data_hdd4t/pcap_process/2020_01_10/中華電信/snort.2020-01-10_dir/snort.log/*.json\"\n",
    "pcap_df_multiline = spark.read.option(\"multiline\", \"true\").json(pcapPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新整理schema\n",
    "# layer_df = pcap_df_multiline.select(\"_source.layers.`ip.src`\")\n",
    "# src_ip_df = layer_df.select(\"`ip.src`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_ip_df = pcap_df_multiline.select(\"_source.layers.`ip.src`\")\n",
    "src_ip_df.createOrReplaceTempView(\"src_ip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算當日不重複IP數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinctquery = (spark.sql(\"SELECT COUNT(DISTINCT `ip.src`) FROM src_ip\"))\n",
    "distinctresult = distinctquery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算當日流量 Top 10 IP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxflowquery = (spark.sql(\"SELECT `ip.src`, COUNT(*) FROM src_ip GROUP BY `ip.src` ORDER BY COUNT(*) DESC LIMIT 10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接拿maxflowquery來畫圖\n",
    "maxflowresult = maxflowquery.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxflowresult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算單一IP在特定time interval (e.g. second, minute, hour)下最多封包數量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pcap_df_multiline.select(\"_source.layers.`ip.src`\",\"_source.layers.`frame.time`\")\n",
    "df = pcap_df_multiline.select(f.col(\"_source.layers.`ip.src`\").getItem(0).alias(\"ip.src\"),f.col(\"_source.layers.`frame.time`\").getItem(0).alias(\"frame.time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"frame.time\",f.to_timestamp(f.col(\"`frame.time`\"),\"MMM dd, yyyy HH:mm:ss.SSSSSSSSS z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ip.src: string (nullable = true)\n",
      " |-- frame.time: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_result = df.groupBy(\"`ip.src`\" ,f.window(\"`frame.time`\",\"1 hour\")).count().orderBy('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = hour_result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "with open(\"/home/antslab/spark_data/intermediate/pcap/cht_0110_perhour.pk\", \"wb\") as file:\n",
    "    pk.dump(a, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_result = df.groupBy(\"`ip.src`\" ,f.window(\"`frame.time`\",\"1 milliseconds\")).count().orderBy('window', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ms_result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "with open(\"/home/antslab/spark_data/intermediate/pcap/cht_0110_ms.pk\", \"wb\") as file:\n",
    "    pk.dump(b, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 之前找外部來源IP top10結果 (cht 1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pk\n",
    "# with open(\"cht_0110_top10.pk\", 'wb') as file:\n",
    "#     pk.dump(result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "with open(\"/home/antslab/spark_data/intermediate/pcap/cht_0110_top10.pk\", 'rb') as file:\n",
    "    aresult = pk.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
