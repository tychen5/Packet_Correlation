{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row, SQLContext, SparkSession\n",
    "from pyspark import SparkConf\n",
    "# Import data types\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.setAppName(\"pcap_analyzer\")\n",
    "conf.setMaster(\"k8s://https://192.168.50.123:6443\")\n",
    "conf.set(\"spark.executor.instances\",\"2\")\n",
    "conf.set(\"spark.kubernetes.container.image\", \"smileocean/spark-py:spark_3.0.0_preview2_python\")\n",
    "conf.set(\"spark.kubernetes.namespace\", \"spark-employee\")\n",
    "conf.set(\"spark.kubernetes.authenticate.driver.serviceAccountName\",\"spark-employee\")\n",
    "conf.set(\"spark.kubernetes.pyspark.pythonVersion\",\"3\")\n",
    "spark = SparkSession.builder.appName(\"pcap_analyzer\").config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multipleline\n",
    "pcapPath = \"/home/antslab/data_hdd4t/中華電信/pcap/snort.2020-01-10_dir/snort.log/outbound_*.json\"\n",
    "pcap_df_multiline = spark.read.option(\"multiline\", \"true\").json(pcapPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新整理schema\n",
    "# layer_df = pcap_df_multiline.select(\"_source.layers.`ip.src`\")\n",
    "# src_ip_df = layer_df.select(\"`ip.src`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_ip_df = pcap_df_multiline.select(\"_source.layers.`ip.src`\")\n",
    "src_ip_df.createOrReplaceTempView(\"src_ip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxflowquery = (spark.sql(\"SELECT `ip.src`, COUNT(*) FROM src_ip GROUP BY `ip.src` ORDER BY COUNT(*) DESC LIMIT 10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接拿maxflowquery來畫圖\n",
    "result = maxflowquery.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "with open(\"cht_0110_top10.pk\", 'wb') as file:\n",
    "    pk.dump(result, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "with open(\"/home/antslab/spark_data/intermediate/pcap/cht_0110_top10.pk\", 'rb') as file:\n",
    "    result = pk.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
