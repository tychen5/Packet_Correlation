{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/antslab/anaconda3/bin/python\n",
      "3.7.7 (default, Mar 26 2020, 15:48:22) \n",
      "[GCC 7.3.0]\n",
      "sys.version_info(major=3, minor=7, micro=7, releaselevel='final', serial=0)\n",
      "0.31.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.0.0-preview2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " import sys,os\n",
    " print(sys.executable)\n",
    " print(sys.version)\n",
    " print(sys.version_info)\n",
    "import findspark\n",
    "os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3' #'/home/antslab/anaconda3/bin/python'\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.setAppName(\"pcapAnalyzer\")#pcap_analyzer pcapAnalyzer\n",
    "conf.setMaster(\"k8s://https://192.168.50.123:6443\")\n",
    "conf.set(\"spark.executor.instances\",\"2\") #2\n",
    "conf.set(\"spark.kubernetes.container.image\", \"smileocean/spark-py:spark_3.0.0_preview2_python\")\n",
    "conf.set(\"spark.kubernetes.namespace\", \"spark-employee\") #spark-employee\n",
    "conf.set(\"spark.kubernetes.authenticate.driver.serviceAccountName\",\"spark-employee\")#spark-employee\n",
    "conf.set(\"spark.kubernetes.pyspark.pythonVersion\",\"3\")\n",
    "conf.set(\"spark.executor.cores\",\"12\")\n",
    "conf.set(\"spark.driver.memory\",\"10g\")\n",
    "conf.set(\"spark.memory.storageFraction\",\"0.2\")\n",
    "conf.set(\"spark.driver.maxResultSize\",\"0\")\n",
    "conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "from pyspark.conf import SparkConf\n",
    "spark = SparkSession.builder.appName(\"pcapAnalyzer\").config(conf=conf).getOrCreate() \n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", True)\n",
    "\n",
    "import databricks.koalas as ks\n",
    "ks.options.display.max_rows = 10\n",
    "ks.set_option('compute.max_rows', None)\n",
    "ks.set_option('compute.ops_on_diff_frames', True)\n",
    "ks.set_option('compute.default_index_type', 'distributed')\n",
    "print(ks.__version__)\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Error: b'' ! Done: b''\n",
      "!Error: b\"Unable to use a TTY - input is not a terminal or the right kind of file\\nput: `/kkk.txt': File exists\\ncommand terminated with exit code 1\\n\" ! Done: b''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "cmd = [\"kubectl\",\"cp\", '/tmp/kkk.txt', \"hadoop/k8s-hadoop-master:/tmp/\"]\n",
    "p = subprocess.Popen(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE, shell=False)\n",
    "out, err = p.communicate()\n",
    "print(\"!Error:\", err, '! Done:',out)\n",
    "cmd = [\"kubectl\",\"exec\",\"-it\",\"k8s-hadoop-master\",\"--namespace=hadoop\",\"--\",\n",
    "       \"hdfs\",\"dfs\",\"-put\",\"/tmp/kkk.txt\",\"/\"]\n",
    "p = subprocess.Popen(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE, shell=False)\n",
    "out, err = p.communicate()\n",
    "print(\"!Error:\", err, '! Done:',out)\n",
    "spark.read.text('hdfs://hadoop-master:9000/kkk.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!Error: b'Unable to use a TTY - input is not a terminal or the right kind of file\\n2020-04-15 14:38:39,900 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\\n' ! Done: b''\n",
    "!Error: b\"Unable to use a TTY - input is not a terminal or the right kind of file\\nput: `/data/': No such file or directory: `hdfs://hadoop-master:9000/data'\\ncommand terminated with exit code 1\\n\" ! Done: b''\n",
    "\n",
    "!Error: b\"Unable to use a TTY - input is not a terminal or the right kind of file\\nput: `/kkk.txt': File exists\\ncommand terminated with exit code 1\\n\" ! Done: b''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!Error: b'Unable to use a TTY - input is not a terminal or the right kind of file\\n' ! Done: b''\n"
     ]
    }
   ],
   "source": [
    "cmd = [\"kubectl\",\"exec\",\"-it\",\"k8s-hadoop-master\",\"--namespace=hadoop\",\"--\",\n",
    "       \"hdfs\",\"dfs\",\"-mkdir\",\"/honeypot/kkk/\"]\n",
    "p = subprocess.Popen(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE, shell=False)\n",
    "out, err = p.communicate()\n",
    "print(\"!Error:\", err, '! Done:',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out == b''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[value: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.text('hdfs://hadoop-master:9000/kkk.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
